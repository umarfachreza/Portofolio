{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Outcome'],axis=1)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_report_by_algo(x,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y)\n",
    "    model=[LogisticRegression,DecisionTreeClassifier,RandomForestClassifier,GradientBoostingClassifier]\n",
    "    for item in model:\n",
    "        clf=item()\n",
    "        clf.fit(X_train,y_train)\n",
    "        prediction_test = clf.predict(X_test)\n",
    "        prediction_train = clf.predict(X_train)\n",
    "        print(item)\n",
    "        print('class report data test')\n",
    "        print(classification_report(y_test,prediction_test))\n",
    "        print('============================================')\n",
    "        print('class report data train')\n",
    "        print(classification_report(y_train,prediction_train))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82       126\n",
      "           1       0.68      0.48      0.57        66\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.72      0.68      0.69       192\n",
      "weighted avg       0.74      0.74      0.73       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       374\n",
      "           1       0.74      0.57      0.65       202\n",
      "\n",
      "    accuracy                           0.78       576\n",
      "   macro avg       0.77      0.73      0.74       576\n",
      "weighted avg       0.78      0.78      0.77       576\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       126\n",
      "           1       0.62      0.61      0.61        66\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.71      0.70      0.70       192\n",
      "weighted avg       0.73      0.73      0.73       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       374\n",
      "           1       1.00      1.00      1.00       202\n",
      "\n",
      "    accuracy                           1.00       576\n",
      "   macro avg       1.00      1.00      1.00       576\n",
      "weighted avg       1.00      1.00      1.00       576\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       126\n",
      "           1       0.62      0.48      0.54        66\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.69      0.66      0.67       192\n",
      "weighted avg       0.71      0.72      0.71       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       374\n",
      "           1       1.00      0.98      0.99       202\n",
      "\n",
      "    accuracy                           0.99       576\n",
      "   macro avg       0.99      0.99      0.99       576\n",
      "weighted avg       0.99      0.99      0.99       576\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80       126\n",
      "           1       0.63      0.55      0.59        66\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.70      0.69      0.69       192\n",
      "weighted avg       0.73      0.73      0.73       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       374\n",
      "           1       0.95      0.87      0.91       202\n",
      "\n",
      "    accuracy                           0.94       576\n",
      "   macro avg       0.94      0.92      0.93       576\n",
      "weighted avg       0.94      0.94      0.94       576\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "class_report_by_algo(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.651042\n",
       "1    0.348958\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Outcome.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_data=df[df['Outcome']==1]\n",
    "mayority_data=df[df['Outcome']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_for_mayority=np.random.choice(mayority_data.index,len(minority_data))\n",
    "df_class_0=df.loc[index_for_mayority]\n",
    "undersampling_df=pd.concat([df_class_0,minority_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    268\n",
       "0    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampling_df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_u = undersampling_df.drop(['Outcome'],axis=1)\n",
    "y_u = undersampling_df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76        61\n",
      "           1       0.85      0.64      0.73        73\n",
      "\n",
      "    accuracy                           0.75       134\n",
      "   macro avg       0.76      0.76      0.75       134\n",
      "weighted avg       0.77      0.75      0.74       134\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       207\n",
      "           1       0.78      0.74      0.76       195\n",
      "\n",
      "    accuracy                           0.77       402\n",
      "   macro avg       0.77      0.77      0.77       402\n",
      "weighted avg       0.77      0.77      0.77       402\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67        61\n",
      "           1       0.73      0.67      0.70        73\n",
      "\n",
      "    accuracy                           0.69       134\n",
      "   macro avg       0.69      0.69      0.69       134\n",
      "weighted avg       0.69      0.69      0.69       134\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       207\n",
      "           1       1.00      1.00      1.00       195\n",
      "\n",
      "    accuracy                           1.00       402\n",
      "   macro avg       1.00      1.00      1.00       402\n",
      "weighted avg       1.00      1.00      1.00       402\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76        61\n",
      "           1       0.83      0.68      0.75        73\n",
      "\n",
      "    accuracy                           0.75       134\n",
      "   macro avg       0.76      0.76      0.75       134\n",
      "weighted avg       0.77      0.75      0.75       134\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       207\n",
      "           1       0.99      0.98      0.99       195\n",
      "\n",
      "    accuracy                           0.99       402\n",
      "   macro avg       0.99      0.99      0.99       402\n",
      "weighted avg       0.99      0.99      0.99       402\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.74        61\n",
      "           1       0.80      0.73      0.76        73\n",
      "\n",
      "    accuracy                           0.75       134\n",
      "   macro avg       0.75      0.76      0.75       134\n",
      "weighted avg       0.76      0.75      0.75       134\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       207\n",
      "           1       0.96      0.96      0.96       195\n",
      "\n",
      "    accuracy                           0.97       402\n",
      "   macro avg       0.97      0.97      0.97       402\n",
      "weighted avg       0.97      0.97      0.97       402\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "class_report_by_algo(x_u,y_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_report_by_algo_ROS(x,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y)\n",
    "    ros=RandomOverSampler()\n",
    "    X_ros,y_ros=ros.fit_sample(X_train,y_train)\n",
    "    X_ros=pd.DataFrame(X_ros,columns=x.columns)\n",
    "    model=[LogisticRegression,DecisionTreeClassifier,RandomForestClassifier,GradientBoostingClassifier]\n",
    "    for item in model:\n",
    "        clf=item()\n",
    "        clf.fit(X_ros,y_ros)\n",
    "        prediction_test = clf.predict(X_test)\n",
    "        prediction_train = clf.predict(X_ros)\n",
    "        print(item)\n",
    "        print('class report data test')\n",
    "        print(classification_report(y_test,prediction_test))\n",
    "        print('============================================')\n",
    "        print('class report data train')\n",
    "        print(classification_report(y_ros,prediction_train))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78       124\n",
      "           1       0.60      0.69      0.64        68\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.71      0.72      0.71       192\n",
      "weighted avg       0.74      0.73      0.73       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79       376\n",
      "           1       0.80      0.78      0.79       376\n",
      "\n",
      "    accuracy                           0.79       752\n",
      "   macro avg       0.79      0.79      0.79       752\n",
      "weighted avg       0.79      0.79      0.79       752\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       124\n",
      "           1       0.51      0.51      0.51        68\n",
      "\n",
      "    accuracy                           0.66       192\n",
      "   macro avg       0.62      0.62      0.62       192\n",
      "weighted avg       0.66      0.66      0.66       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       376\n",
      "           1       1.00      1.00      1.00       376\n",
      "\n",
      "    accuracy                           1.00       752\n",
      "   macro avg       1.00      1.00      1.00       752\n",
      "weighted avg       1.00      1.00      1.00       752\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       124\n",
      "           1       0.62      0.51      0.56        68\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.69      0.67      0.68       192\n",
      "weighted avg       0.71      0.72      0.71       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       376\n",
      "           1       1.00      0.99      0.99       376\n",
      "\n",
      "    accuracy                           0.99       752\n",
      "   macro avg       0.99      0.99      0.99       752\n",
      "weighted avg       0.99      0.99      0.99       752\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78       124\n",
      "           1       0.60      0.69      0.64        68\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.71      0.72      0.71       192\n",
      "weighted avg       0.74      0.73      0.73       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       376\n",
      "           1       0.90      0.95      0.93       376\n",
      "\n",
      "    accuracy                           0.93       752\n",
      "   macro avg       0.93      0.93      0.93       752\n",
      "weighted avg       0.93      0.93      0.93       752\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "class_report_by_algo_ROS(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_report_by_algo_smote(x,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y)\n",
    "    sm=SMOTE(random_state=101)\n",
    "    X_sm,y_sm=sm.fit_sample(X_train,y_train)\n",
    "    model=[LogisticRegression,DecisionTreeClassifier,RandomForestClassifier,GradientBoostingClassifier]\n",
    "    for item in model:\n",
    "        clf=item()\n",
    "        clf.fit(X_sm,y_sm)\n",
    "        prediction_test = clf.predict(X_test)\n",
    "        prediction_train = clf.predict(X_sm)\n",
    "        print(item)\n",
    "        print('class report data test')\n",
    "        print(classification_report(y_test,prediction_test))\n",
    "        print('============================================')\n",
    "        print('class report data train')\n",
    "        print(classification_report(y_sm,prediction_train))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       119\n",
      "           1       0.64      0.62      0.63        73\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.71      0.70      0.70       192\n",
      "weighted avg       0.72      0.72      0.72       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79       381\n",
      "           1       0.79      0.78      0.78       381\n",
      "\n",
      "    accuracy                           0.78       762\n",
      "   macro avg       0.78      0.78      0.78       762\n",
      "weighted avg       0.78      0.78      0.78       762\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       119\n",
      "           1       0.57      0.51      0.54        73\n",
      "\n",
      "    accuracy                           0.67       192\n",
      "   macro avg       0.64      0.64      0.64       192\n",
      "weighted avg       0.66      0.67      0.66       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       381\n",
      "           1       1.00      1.00      1.00       381\n",
      "\n",
      "    accuracy                           1.00       762\n",
      "   macro avg       1.00      1.00      1.00       762\n",
      "weighted avg       1.00      1.00      1.00       762\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.80       119\n",
      "           1       0.69      0.66      0.67        73\n",
      "\n",
      "    accuracy                           0.76       192\n",
      "   macro avg       0.74      0.74      0.74       192\n",
      "weighted avg       0.75      0.76      0.75       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       381\n",
      "           1       0.99      0.98      0.99       381\n",
      "\n",
      "    accuracy                           0.99       762\n",
      "   macro avg       0.99      0.99      0.99       762\n",
      "weighted avg       0.99      0.99      0.99       762\n",
      "\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       119\n",
      "           1       0.62      0.70      0.66        73\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.71      0.72      0.71       192\n",
      "weighted avg       0.73      0.72      0.73       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       381\n",
      "           1       0.92      0.96      0.94       381\n",
      "\n",
      "    accuracy                           0.94       762\n",
      "   macro avg       0.94      0.94      0.94       762\n",
      "weighted avg       0.94      0.94      0.94       762\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "class_report_by_algo_smote(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASS WEIGHT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_Weight_by_LogisticRegression(x,y,weight):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y,random_state=101)\n",
    "    clf=LogisticRegression(random_state = 101, class_weight = weight)\n",
    "    clf.fit(X_train,y_train)\n",
    "    prediction_test = clf.predict(X_test)\n",
    "    prediction_train = clf.predict(X_train)\n",
    "    print('class report data test')\n",
    "    print(classification_report(y_test,prediction_test))\n",
    "    print('============================================')\n",
    "    print('class report data train')\n",
    "    print(classification_report(y_train,prediction_train))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.60      0.72       124\n",
      "           1       0.55      0.87      0.67        68\n",
      "\n",
      "    accuracy                           0.70       192\n",
      "   macro avg       0.72      0.74      0.70       192\n",
      "weighted avg       0.77      0.70      0.70       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.62      0.73       376\n",
      "           1       0.54      0.86      0.67       200\n",
      "\n",
      "    accuracy                           0.70       576\n",
      "   macro avg       0.72      0.74      0.70       576\n",
      "weighted avg       0.77      0.70      0.71       576\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "class_Weight_by_LogisticRegression(x,y,{0:1,1:3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionsTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_Weight_by_dTree(x,y,weight,depth):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y,random_state=101)\n",
    "    clf=DecisionTreeClassifier(random_state = 101, class_weight = weight,max_depth=depth)\n",
    "    clf.fit(X_train,y_train)\n",
    "    prediction_test = clf.predict(X_test)\n",
    "    prediction_train = clf.predict(X_train)\n",
    "    print('class report data test')\n",
    "    print(classification_report(y_test,prediction_test))\n",
    "    print('============================================')\n",
    "    print('class report data train')\n",
    "    print(classification_report(y_train,prediction_train))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.58      0.70       124\n",
      "           1       0.53      0.87      0.66        68\n",
      "\n",
      "    accuracy                           0.68       192\n",
      "   macro avg       0.71      0.72      0.68       192\n",
      "weighted avg       0.76      0.68      0.69       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.62      0.75       376\n",
      "           1       0.56      0.91      0.69       200\n",
      "\n",
      "    accuracy                           0.72       576\n",
      "   macro avg       0.74      0.77      0.72       576\n",
      "weighted avg       0.80      0.72      0.73       576\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_Weight_by_dTree(x,y,{0:1,1:2},3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_Weight_by_Randomforest(x,y,weight,depth):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y,random_state=101)\n",
    "    clf=RandomForestClassifier(random_state = 101, class_weight = weight,max_depth=depth)\n",
    "    clf.fit(X_train,y_train)\n",
    "    prediction_test = clf.predict(X_test)\n",
    "    prediction_train = clf.predict(X_train)\n",
    "    print('class report data test')\n",
    "    print(classification_report(y_test,prediction_test))\n",
    "    print('============================================')\n",
    "    print('class report data train')\n",
    "    print(classification_report(y_train,prediction_train))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.66      0.75       124\n",
      "           1       0.57      0.82      0.67        68\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.72      0.74      0.71       192\n",
      "weighted avg       0.77      0.72      0.72       192\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76       376\n",
      "           1       0.57      0.85      0.69       200\n",
      "\n",
      "    accuracy                           0.73       576\n",
      "   macro avg       0.73      0.76      0.72       576\n",
      "weighted avg       0.78      0.73      0.73       576\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "class_Weight_by_Randomforest(x,y,{0:1,1:2},3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DARI MODEL Diatas didapat model terbaik menggunakan DecisionTree dengan class_weight={0:1,1:2} dan Max_depth = 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
